"""
ìˆ˜ìš”ì˜ˆì¸¡ ì„¤ëª… ì—ì´ì „íŠ¸ (Forecast Explanation Agent)
Claude Tool Use ê¸°ë°˜ êµ¬í˜„
"""

import os
import json
from typing import List, Dict, Any, Optional
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv(os.path.join(os.path.dirname(__file__), '..', '.env'))

from anthropic import Anthropic

try:
    from .tools import TOOL_DEFINITIONS, execute_tool
except ImportError:
    from tools import TOOL_DEFINITIONS, execute_tool

# Anthropic í´ë¼ì´ì–¸íŠ¸
client = Anthropic()

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
SYSTEM_PROMPT = """You are a smartphone demand forecasting explanation agent.

Your role is to explain WHY the demand forecast model made certain predictions,
using evidence from news data, product releases, and economic indicators.

## Guidelines

1. **Evidence-based explanations**: Always ground your explanations in data from the tools.
   - Use get_shap_values to understand which factors contributed most
   - Use search_news and get_news_summary to find supporting evidence
   - Use get_product_releases for product launch context
   - Use get_macro_indicators for economic context

2. **Quantify impact**: When possible, include numbers and percentages
   - "ê²½ì œ ë‰´ìŠ¤ í†¤ì´ -2.5ë¡œ ì „ë¶„ê¸° ëŒ€ë¹„ 30% ì•…í™”"
   - "ê´€ë ¨ ê¸°ì‚¬ 450ê±´ ì¤‘ 65%ê°€ ë¶€ì •ì "

3. **Cite sources**: Reference specific news sources or events when relevant

4. **Business-friendly language**: Avoid technical jargon, use clear Korean explanations

5. **Structured responses**: Organize explanations with clear sections:
   - í•µì‹¬ ìš”ì•½ (1-2 sentences)
   - ì£¼ìš” ì›ì¸ ë¶„ì„ (numbered list with contribution %)
   - ê´€ë ¨ ë‰´ìŠ¤/ì´ë²¤íŠ¸
   - ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ (optional)

## Taxonomy

**Regions** (Counterpoint Research standard):
- North America, Western Europe, Central Europe
- China, India, Japan, South Korea, Southeast Asia
- MEA (Middle East & Africa), CALA (Caribbean & Latin America)
- Asia Pacific Others

**Segments**:
- entry: ì €ê°€ (ë³´ê¸‰í˜•)
- mid-range: ì¤‘ê°€ (ì¤‘ê¸‰í˜•)
- flagship: ê³ ê°€ (í”„ë¦¬ë¯¸ì—„)

**External Factors**:
- geopolitics: ì§€ì •í•™ì  ìš”ì¸ (ë¶„ìŸ, ì œì¬, ë¬´ì—­ë¶„ìŸ)
- economy: ê²½ì œì  ìš”ì¸ (ì¸í”Œë ˆì´ì…˜, ê¸ˆë¦¬, í™˜ìœ¨)
- supply_chain: ê³µê¸‰ë§ (ë°˜ë„ì²´, ë¬¼ë¥˜, ë¶€í’ˆ)
- regulation: ê·œì œ (ë²•ë¥ , ê¸ˆì§€, ë…ì ê·œì œ)
- disaster: ì¬ë‚œ (íŒ¬ë°ë¯¹, ìì—°ì¬í•´)

## Response Format

Always respond in Korean unless the user asks in English.
Use markdown formatting for better readability.
"""


def process_tool_calls(tool_calls: List[Dict]) -> List[Dict]:
    """Tool í˜¸ì¶œ ì²˜ë¦¬"""
    results = []
    for tool_call in tool_calls:
        tool_name = tool_call.name
        tool_input = tool_call.input

        print(f"  [Tool] {tool_name}({json.dumps(tool_input, ensure_ascii=False)[:100]}...)")

        result = execute_tool(tool_name, tool_input)
        results.append({
            "type": "tool_result",
            "tool_use_id": tool_call.id,
            "content": json.dumps(result, ensure_ascii=False, default=str)
        })

    return results


def chat(
    user_message: str,
    conversation_history: List[Dict] = None,
    model: str = "claude-sonnet-4-20250514"
) -> tuple[str, List[Dict]]:
    """
    ì‚¬ìš©ì ë©”ì‹œì§€ì— ì‘ë‹µ

    Args:
        user_message: ì‚¬ìš©ì ì§ˆë¬¸
        conversation_history: ì´ì „ ëŒ€í™” ë‚´ì—­
        model: ì‚¬ìš©í•  Claude ëª¨ë¸

    Returns:
        (ì‘ë‹µ í…ìŠ¤íŠ¸, ì—…ë°ì´íŠ¸ëœ ëŒ€í™” ë‚´ì—­)
    """
    if conversation_history is None:
        conversation_history = []

    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    conversation_history.append({
        "role": "user",
        "content": user_message
    })

    # Claude API í˜¸ì¶œ
    response = client.messages.create(
        model=model,
        max_tokens=4096,
        system=SYSTEM_PROMPT,
        tools=TOOL_DEFINITIONS,
        messages=conversation_history
    )

    # Tool í˜¸ì¶œì´ ìˆìœ¼ë©´ ì²˜ë¦¬
    while response.stop_reason == "tool_use":
        # Assistant ë©”ì‹œì§€ ì €ì¥
        conversation_history.append({
            "role": "assistant",
            "content": response.content
        })

        # Tool í˜¸ì¶œ ì¶”ì¶œ ë° ì‹¤í–‰
        tool_calls = [block for block in response.content if block.type == "tool_use"]
        tool_results = process_tool_calls(tool_calls)

        # Tool ê²°ê³¼ ì¶”ê°€
        conversation_history.append({
            "role": "user",
            "content": tool_results
        })

        # ë‹¤ì‹œ API í˜¸ì¶œ
        response = client.messages.create(
            model=model,
            max_tokens=4096,
            system=SYSTEM_PROMPT,
            tools=TOOL_DEFINITIONS,
            messages=conversation_history
        )

    # ìµœì¢… ì‘ë‹µ ì¶”ì¶œ
    final_response = ""
    for block in response.content:
        if hasattr(block, "text"):
            final_response += block.text

    # Assistant ì‘ë‹µ ì €ì¥
    conversation_history.append({
        "role": "assistant",
        "content": response.content
    })

    return final_response, conversation_history


def interactive_chat():
    """ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤"""
    print("=" * 60)
    print("ğŸ“± ìŠ¤ë§ˆíŠ¸í° ìˆ˜ìš”ì˜ˆì¸¡ ì„¤ëª… ì—ì´ì „íŠ¸")
    print("=" * 60)
    print("ì˜ˆì‹œ ì§ˆë¬¸:")
    print("  - ë¶ë¯¸ flagship ìˆ˜ìš” í•˜ë½ ì›ì¸ì€?")
    print("  - ì¤‘êµ­ ì‹œì¥ ì§€ì •í•™ ë¦¬ìŠ¤í¬ ì˜í–¥ ë¶„ì„í•´ì¤˜")
    print("  - 2020ë…„ 1ë¶„ê¸° ì¸ë„ ì‹œì¥ ìƒí™© ì„¤ëª…í•´ì¤˜")
    print("-" * 60)
    print("ì¢…ë£Œ: 'quit' ë˜ëŠ” 'exit' ì…ë ¥")
    print("=" * 60)

    conversation_history = []

    while True:
        try:
            user_input = input("\nğŸ§‘ You: ").strip()
        except (EOFError, KeyboardInterrupt):
            print("\nğŸ‘‹ ì•ˆë…•íˆ ê°€ì„¸ìš”!")
            break

        if not user_input:
            continue

        if user_input.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
            print("ğŸ‘‹ ì•ˆë…•íˆ ê°€ì„¸ìš”!")
            break

        print("\nğŸ¤– Agent: ", end="")
        try:
            response, conversation_history = chat(user_input, conversation_history)
            print(response)
        except Exception as e:
            print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ëŒ€í™” ì´ˆê¸°í™”
            conversation_history = []


def single_query(query: str) -> str:
    """ë‹¨ì¼ ì§ˆë¬¸ ì²˜ë¦¬"""
    response, _ = chat(query)
    return response


if __name__ == "__main__":
    import sys

    if len(sys.argv) > 1:
        # ëª…ë ¹ì¤„ ì¸ìë¡œ ì§ˆë¬¸ ì „ë‹¬
        query = " ".join(sys.argv[1:])
        print(f"Query: {query}\n")
        print(single_query(query))
    else:
        # ëŒ€í™”í˜• ëª¨ë“œ
        interactive_chat()
